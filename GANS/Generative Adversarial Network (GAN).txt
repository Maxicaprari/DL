Generative Adversarial Network (GAN)
GAN’s architecture consists of two neural networks:
1. Generator: creates synthetic data from random noise to produce data so realistic that the discriminator cannot distinguish it from real data.
2. Discriminator: acts as a critic, evaluating whether the data it receives is real or fake.
  

DETAILED ARCHITECTURE OF GANs


1. Generator Model
The generator is a deep neural network that takes random noise as input to generate realistic data samples (e.g., images or text). It learns the underlying data distribution by adjusting its parameters through backpropagation.
The generator’s objective is to produce samples that the discriminator classifies as real. The loss function is:
  



2. Discriminator Model
The discriminator acts as a binary classifier, distinguishing between real and generated data. It learns to improve its classification ability through training, refining its parameters to detect fake samples more accurately.
When dealing with image data, the discriminator often employs convolutional layers or other relevant architectures suited to the data type. These layers help extract features and enhance the model’s ability to differentiate between real and generated samples.
The discriminator reduces the negative log likelihood of correctly classifying both produced and real samples. This loss incentivizes the discriminator to accurately categorize generated samples as fake and real samples with the following equation:
  



MinMax Loss
GANs follow a minimax optimization where the generator and discriminator are adversaries:
  





  

How does a GAN work?
Let’s understand how the generator (G) and discriminator (D) complete to improve each other over time:
1. Generator’s First Move
G takes a random noise vector as input. This noise vector contains random values and acts as the starting point for G’s creation process. Using its internal layers and learned patterns, G transforms the noise vector into a new data sample, like a generated image.
2. Discriminator’s Turn
D receives two kinds of inputs:
* Real data samples from the training dataset.
* The data samples generated by G in the previous step.
D’s job is to analyze each input and determine whether it’s real data or something G cooked up. It outputs a probability score between 0 and 1. A score of 1 indicates the data is likely real, and 0 suggests it’s fake.
3. Adversarial Learning
* If the discriminator correctly classifies real data as real and fake data as fake, it strengthens its ability slightly.
* If the generator successfully fools the discriminator, it receives a positive update, while the discriminator is penalized.
5. Generator’s Improvement
Every time the discriminator misclassifies fake data as real, the generator learns and improves. Over multiple iterations, the generator produces more convincing synthetic samples.
6. Discriminator’s Adaptation
The discriminator continuously refines its ability to distinguish real from fake data. This ongoing duel between the generator and discriminator enhances the overall model’s learning process.
7. Training Progression
* As training continues, the generator becomes highly proficient at producing realistic data.
* Eventually, the discriminator struggles to distinguish real from fake, indicating that the GAN has reached a well-trained state.
* At this point, the generator can be used to generate high-quality synthetic data for various applications.